MySQL(),
dbname = databaseName,
host = dbGlobalConfig$host,
port = dbGlobalConfig$port,
user = dbGlobalConfig$user,
password = dbGlobalConfig$password
)
# Construct the fetching query
query <- sprintf("SELECT * FROM %s", tableName)
# Submit the fetch query and disconnect
datos_app <- dbGetQuery(db, query)
#Desconectarnos de la base de datos
dbDisconnect(db)
return(datos_app)
}
# Inspector G croquis phase
attach(mtcars)
layout(matrix(c(1, 2, 3, 4, 5), 5, 1, byrow = TRUE))
par(mar=c(0.8, 0.8, 0.8, 0.8))
## Part 0: ask for model result, district, locality, and date of path
modelResultName <- "MODEL_RESULTS_13.58_2017-10-03_MODEL_RESULTS_13.59_2017-10-03_MODEL_RESULTS_13.60_2017-10-03.combined"
sectionN <- "0"
district <- "13"
localities_vec <- "58,59,60"
localities_vec <- strsplit(localities_vec, ',')[[1]]
localities_vec <- gsub(' ', '', localities_vec)
localities_vec <- gsub('"', '', localities_vec)
localities_vec <- gsub("'", '', localities_vec)
cutoffDate <- "2017-12-11"
pathDate <- "2017-12-11"
userActive <- "7"
## Part I: Load data model results, active data for this day
modelResult <- read.csv(file.path("~/PETM-shiny/graph_partition/newModelResults", paste0(modelResultName, ".csv")), sep=" ")
modelResult <- modelResult[which(modelResult$section == as.numeric(sectionN)),]
# load data, change all variables to characters, filter for district and locality,
# check for integrity of data
activedata <- LoadDataAPP()
province="1"
activedata <- data.frame(lapply(activedata, as.character), stringsAsFactors=FALSE)
stopifnot(!is.null(district))
stopifnot(!is.null(localities_vec))
stopifnot(length(province) == 1)
stopifnot(length(district) == 1)
unicodeFilter <- paste0('^', province, '\\.', district, '\\.', localities_vec, '\\.')
unicodeFilter <- paste0(unicodeFilter, collapse = '|') #match any locality pattern
# if there is no active data that matches pattern
matchingRowsInActiveData <- which(grepl(x=activedata$UNI_CODE, pattern = unicodeFilter))
cat(' Records in SQL: ', length(matchingRowsInActiveData), '\n')
# if there is active data, keep just inspected houses and real data (not test
# data) and also delete all houses with no FECHA information
activedata <- activedata[matchingRowsInActiveData,]
inspectedHouses <- activedata$STATUS_INSPECCION %in% c('I', 'inspeccion')
realData        <- activedata$TEST_DATA == "0"
activedata <- activedata[which(inspectedHouses & realData),]
activedata <- activedata[which(!is.na(activedata$FECHA)),]
cat(' True inspections:', nrow(activedata), '\n')
# check that FECHAS are fine for this locality
fecha <- as.Date(x = activedata$FECHA, format = '%Y-%m-%d')
fechaErrorRowNum <- which(is.na(fecha))
if(length(fechaErrorRowNum) > 0) {
print('Fechas de los inspecciones deben use el formato 2017-12-31')
}
# get INSP_POSITIVA column from activedata
activedata$TOT_INTRA <- gsub(' ', '', activedata$TOT_INTRA)
activedata$TOT_PERI <- gsub(' ', '', activedata$TOT_PERI)
activedata$TOT_INTRA <- ifelse(is.na(activedata$TOT_INTRA) | activedata$TOT_INTRA == "NA",
"0",
activedata$TOT_INTRA)
activedata$TOT_PERI <- ifelse(is.na(activedata$TOT_PERI) | activedata$TOT_PERI == "NA",
"0",
activedata$TOT_PERI)
activedata$INSP_POSITIVA <- ifelse(!is.na(activedata$TOT_INTRA) & !is.na(activedata$TOT_PERI) &
!is.null(activedata$TOT_INTRA) & !is.null(activedata$TOT_PERI) &
!activedata$TOT_INTRA == "NA" & !activedata$TOT_PERI == "NA" &
!activedata$TOT_INTRA == "NULL" & !activedata$TOT_PERI == "NULL" &
as.numeric(activedata$TOT_INTRA) + as.numeric(activedata$TOT_PERI) > 0,
"1",
"0")
# save active data
sactivedata <- activedata
#===================================================================================
#	First day
#===================================================================================
# save all inspections from cutoff date to the path date
fromCutOffDate <- activedata[which(activedata$FECHA >= as.character(as.Date(cutoffDate, "%Y-%m-%d")) &
activedata$FECHA < as.character(as.Date(pathDate, "%Y-%m-%d"))),]
# subset to only those inspecciones that were done on the pathDate day
activedata <- activedata[which(activedata$FECHA == as.character(as.Date(pathDate, "%Y-%m-%d"))),]
# get only those houses of the username we want
activedata <- activedata[which(activedata$USER_NAME == paste0("r", userActive) | activedata$USER_NAME == paste0("R", userActive)),]
fromCutOffDate <- fromCutOffDate[which(fromCutOffDate$USER_NAME == paste0("r", userActive) | fromCutOffDate$USER_NAME == paste0("R", userActive)),]
# order everything by FECHA
activedata <- activedata[order(as.POSIXct(activedata$DATETIME, format = "%Y-%m-%d %H:%M:%S")),]
# delete all duplicated rows
fromCutOffDate <- fromCutOffDate[!duplicated(fromCutOffDate$UNI_CODE),]
activedata <- activedata[!duplicated(activedata$UNI_CODE),]
## Part II: get quantiles of model output
# make quantiles from the modelOutput probabilities
colPalFuncOutput <- colorRampPalette(
colors = c("#FFFFB2", "#FECC5C", "#FD8D3C", "#F03B20", "#BD0026"),
space = "Lab" # Option used when colors do not represent a quantitative scale
)
# colors used for risk map
outputColors <- colPalFuncOutput(5)
quants <- quantile(modelResult$probability, c(0.20, 0.40, 0.60, 0.80))
modelResult$quant <- with(modelResult, factor(ifelse(probability < quants[1], 0,
ifelse(probability < quants[2], 1,
ifelse(probability < quants[3], 2,
ifelse(probability < quants[4], 3, 4))))))
## Part III: draw the risk map and path
plot(modelResult[,c('LONGITUDE','LATITUDE')], col=outputColors[modelResult$quant], xaxt='n', yaxt='n', ann=FALSE, pch = 19, cex = 0.8, axes=F)
title(main="Day 1", line=-17, cex.main=2.5)
latLongFile <- read.csv(file.path(lat_long_direc, "AQP_GPS_GOOGLE_EARTH_PUNTOS_05_jun_2017.csv"))
latLongFile$UNICODE <- as.character(latLongFile$UNICODE)
activedata$UNI_CODE <- gsub("A", "", activedata$UNI_CODE)
# from path date
activedata$LATITUDE <- NA
activedata$LONGITUDE <- NA
for (k in 1:15) {
if (k == 1) {
activedata$LATITUDE[k] <- latLongFile$LATITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
activedata$LONGITUDE[k] <- latLongFile$LONGITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
Arrows(activedata$LONGITUDE[k], activedata$LATITUDE[k] + 0.00015, activedata$LONGITUDE[k], activedata$LATITUDE[k]+ 0.0002, col="green", code = 1,  arr.type="triangle",arr.width = 0.04,arr.length = 0.03, lwd=1.5 )
} else if (k == 15) {
activedata$LATITUDE[k] <- latLongFile$LATITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
activedata$LONGITUDE[k] <- latLongFile$LONGITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
Arrows(activedata$LONGITUDE[k], activedata$LATITUDE[k] + 0.00015, activedata$LONGITUDE[k], activedata$LATITUDE[k]+ 0.0002, col="blue", code = 1,  arr.type="triangle",arr.width = 0.04,arr.length = 0.03, lwd=1.5 )
} else {
activedata$LATITUDE[k] <- latLongFile$LATITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
activedata$LONGITUDE[k] <- latLongFile$LONGITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
Arrows(activedata$LONGITUDE[k], activedata$LATITUDE[k] + 0.00015, activedata$LONGITUDE[k], activedata$LATITUDE[k]+ 0.0002, col="black", code = 1,  arr.type="triangle",arr.width = 0.04,arr.length = 0.03, lwd=1.5 )
}
}
pc = par("usr")
lines(c(-71.49130, -71.49177),
c(-16.42195, -16.42195))
text(x=mean(c(pc[2]-0.0012, pc[2])),
y=pc[3] + 0.06*(pc[4] - pc[3]),
label="50 m", cex=2)
#===================================================================================
#	Second day
#===================================================================================
# change all variables for the next day
fromCutOffDate <- rbind(fromCutOffDate, activedata)
activedata <- sactivedata
modelResultName <- "MODEL_RESULTS_13.58_2017-12-18_11_DEC_MODEL_RESULTS_13.59_2017-10-03_MODEL_RESULTS_13.60_2017-10-03.combined"
pathDate <- "2017-12-12"
modelResult <- read.csv(file.path("~/PETM-shiny/graph_partition/newModelResults", paste0(modelResultName, ".csv")), sep=" ")
modelResult <- modelResult[which(modelResult$section == as.numeric(sectionN)),]
# subset to only those inspecciones that were done on the pathDate day
activedata <- activedata[which(activedata$FECHA == as.character(as.Date(pathDate, "%Y-%m-%d"))),]
# get only those houses of the username we want
activedata <- activedata[which(activedata$USER_NAME == paste0("r", userActive) | activedata$USER_NAME == paste0("R", userActive)),]
# order everything by FECHA
activedata <- activedata[order(as.POSIXct(activedata$DATETIME, format = "%Y-%m-%d %H:%M:%S")),]
# delete all duplicated rows
activedata <- activedata[!duplicated(activedata$UNI_CODE),]
# make quantiles from the modelOutput probabilities
colPalFuncOutput <- colorRampPalette(
colors = c("#FFFFB2", "#FECC5C", "#FD8D3C", "#F03B20", "#BD0026"),
space = "Lab" # Option used when colors do not represent a quantitative scale
)
# colors used for risk map
outputColors <- colPalFuncOutput(5)
quants <- quantile(modelResult$probability, c(0.20, 0.40, 0.60, 0.80))
modelResult$quant <- with(modelResult, factor(ifelse(probability < quants[1], 0,
ifelse(probability < quants[2], 1,
ifelse(probability < quants[3], 2,
ifelse(probability < quants[4], 3, 4))))))
plot(modelResult[,c('LONGITUDE','LATITUDE')], col=outputColors[modelResult$quant], xaxt='n', yaxt='n', ann=FALSE, pch = 19, cex = 0.8, axes=F)
title(main="Day 2",line=-17, cex.main=2.5)
fromCutOffDate$UNI_CODE <- gsub("A", "", fromCutOffDate$UNI_CODE)
activedata$UNI_CODE <- gsub("A", "", activedata$UNI_CODE)
# from path date
activedata$LATITUDE <- NA
activedata$LONGITUDE <- NA
for (k in 1:12) {
if (k == 1) {
activedata$LATITUDE[k] <- latLongFile$LATITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
activedata$LONGITUDE[k] <- latLongFile$LONGITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
Arrows(activedata$LONGITUDE[k], activedata$LATITUDE[k] + 0.00015, activedata$LONGITUDE[k], activedata$LATITUDE[k]+ 0.0002, col="green", code = 1,  arr.type="triangle",arr.width = 0.04,arr.length = 0.03, lwd=1.5 )
} else if (k == 12) {
activedata$LATITUDE[k] <- latLongFile$LATITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
activedata$LONGITUDE[k] <- latLongFile$LONGITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
Arrows(activedata$LONGITUDE[k], activedata$LATITUDE[k] + 0.00015, activedata$LONGITUDE[k], activedata$LATITUDE[k]+ 0.0002, col="blue", code = 1,  arr.type="triangle",arr.width = 0.04,arr.length = 0.03, lwd=1.5 )
} else {
activedata$LATITUDE[k] <- latLongFile$LATITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
activedata$LONGITUDE[k] <- latLongFile$LONGITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
Arrows(activedata$LONGITUDE[k], activedata$LATITUDE[k] + 0.00015, activedata$LONGITUDE[k], activedata$LATITUDE[k]+ 0.0002, col="black", code = 1,  arr.type="triangle",arr.width = 0.04,arr.length = 0.03, lwd=1.5 )
}
}
pc = par("usr")
lines(c(-71.49130, -71.49177),
c(-16.42195, -16.42195))
text(x=mean(c(pc[2]-0.0012, pc[2])),
y=pc[3] + 0.06*(pc[4] - pc[3]),
label="50 m", cex=2)
#===================================================================================
#	Third day
#===================================================================================
# change all variables for the next day
fromCutOffDate <- rbind(fromCutOffDate, activedata)
activedata <- sactivedata
modelResultName <- "MODEL_RESULTS_13.58_2017-12-18_12_DEC_MODEL_RESULTS_13.59_2017-10-03_MODEL_RESULTS_13.60_2017-10-03.combined"
pathDate <- "2017-12-13"
modelResult <- read.csv(file.path("~/PETM-shiny/graph_partition/newModelResults", paste0(modelResultName, ".csv")), sep=" ")
modelResult <- modelResult[which(modelResult$section == as.numeric(sectionN)),]
# subset to only those inspecciones that were done on the pathDate day
activedata <- activedata[which(activedata$FECHA == as.character(as.Date(pathDate, "%Y-%m-%d"))),]
# get only those houses of the username we want
activedata <- activedata[which(activedata$USER_NAME == paste0("r", userActive) | activedata$USER_NAME == paste0("R", userActive)),]
# order everything by FECHA
activedata <- activedata[order(as.POSIXct(activedata$DATETIME, format = "%Y-%m-%d %H:%M:%S")),]
# delete all duplicated rows
activedata <- activedata[!duplicated(activedata$UNI_CODE),]
# make quantiles from the modelOutput probabilities
colPalFuncOutput <- colorRampPalette(
colors = c("#FFFFB2", "#FECC5C", "#FD8D3C", "#F03B20", "#BD0026"),
space = "Lab" # Option used when colors do not represent a quantitative scale
)
# colors used for risk map
outputColors <- colPalFuncOutput(5)
quants <- quantile(modelResult$probability, c(0.20, 0.40, 0.60, 0.80))
modelResult$quant <- with(modelResult, factor(ifelse(probability < quants[1], 0,
ifelse(probability < quants[2], 1,
ifelse(probability < quants[3], 2,
ifelse(probability < quants[4], 3, 4))))))
plot(modelResult[,c('LONGITUDE','LATITUDE')], col=outputColors[modelResult$quant], xaxt='n', yaxt='n', ann=FALSE, pch = 19, cex = 0.8, axes=F)
title(main="Day 3", line=-17, cex.main=2.5)
fromCutOffDate$UNI_CODE <- gsub("A", "", fromCutOffDate$UNI_CODE)
activedata$UNI_CODE <- gsub("A", "", activedata$UNI_CODE)
# from path date
activedata$LATITUDE <- NA
activedata$LONGITUDE <- NA
for (k in 1:8) {
if (k == 1) {
activedata$LATITUDE[k] <- latLongFile$LATITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
activedata$LONGITUDE[k] <- latLongFile$LONGITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
Arrows(activedata$LONGITUDE[k], activedata$LATITUDE[k] + 0.00015, activedata$LONGITUDE[k], activedata$LATITUDE[k]+ 0.0002, col="green", code = 1,  arr.type="triangle",arr.width = 0.04,arr.length = 0.03, lwd=1.5 )
} else if (k == 8) {
activedata$LATITUDE[k] <- latLongFile$LATITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
activedata$LONGITUDE[k] <- latLongFile$LONGITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
Arrows(activedata$LONGITUDE[k], activedata$LATITUDE[k] + 0.00015, activedata$LONGITUDE[k], activedata$LATITUDE[k]+ 0.0002, col="blue", code = 1,  arr.type="triangle",arr.width = 0.04,arr.length = 0.03, lwd=1.5 )
} else {
activedata$LATITUDE[k] <- latLongFile$LATITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
activedata$LONGITUDE[k] <- latLongFile$LONGITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
Arrows(activedata$LONGITUDE[k], activedata$LATITUDE[k] + 0.00015, activedata$LONGITUDE[k], activedata$LATITUDE[k]+ 0.0002, col="black", code = 1,  arr.type="triangle",arr.width = 0.04,arr.length = 0.03, lwd=1.5 )
}
}
pc = par("usr")
lines(c(-71.49130, -71.49177),
c(-16.42195, -16.42195))
text(x=mean(c(pc[2]-0.0012, pc[2])),
y=pc[3] + 0.06*(pc[4] - pc[3]),
label="50 m", cex=2)
#===================================================================================
#	Fourth day
#===================================================================================
# change all variables for the next day
fromCutOffDate <- rbind(fromCutOffDate, activedata)
activedata <- sactivedata
modelResultName <- "MODEL_RESULTS_13.58_2017-12-19_13_DEC_MODEL_RESULTS_13.59_2017-12-19_13_dec_MODEL_RESULTS_13.60_2017-10-03.combined"
pathDate <- "2017-12-14"
modelResult <- read.csv(file.path("~/PETM-shiny/graph_partition/newModelResults", paste0(modelResultName, ".csv")), sep=" ")
modelResult <- modelResult[which(modelResult$section == as.numeric(sectionN)),]
# subset to only those inspecciones that were done on the pathDate day
activedata <- activedata[which(activedata$FECHA == as.character(as.Date(pathDate, "%Y-%m-%d"))),]
# get only those houses of the username we want
activedata <- activedata[which(activedata$USER_NAME == paste0("r", userActive) | activedata$USER_NAME == paste0("R", userActive)),]
# order everything by FECHA
activedata <- activedata[order(as.POSIXct(activedata$DATETIME, format = "%Y-%m-%d %H:%M:%S")),]
# delete all duplicated rows
activedata <- activedata[!duplicated(activedata$UNI_CODE),]
# make quantiles from the modelOutput probabilities
colPalFuncOutput <- colorRampPalette(
colors = c("#FFFFB2", "#FECC5C", "#FD8D3C", "#F03B20", "#BD0026"),
space = "Lab" # Option used when colors do not represent a quantitative scale
)
# colors used for risk map
outputColors <- colPalFuncOutput(5)
quants <- quantile(modelResult$probability, c(0.20, 0.40, 0.60, 0.80))
modelResult$quant <- with(modelResult, factor(ifelse(probability < quants[1], 0,
ifelse(probability < quants[2], 1,
ifelse(probability < quants[3], 2,
ifelse(probability < quants[4], 3, 4))))))
plot(modelResult[,c('LONGITUDE','LATITUDE')], col=outputColors[modelResult$quant], xaxt='n', yaxt='n', ann=FALSE, pch = 19, cex = 0.8, axes=F)
title(main="Day 4", line=-17, cex.main=2.5)
fromCutOffDate$UNI_CODE <- gsub("A", "", fromCutOffDate$UNI_CODE)
activedata$UNI_CODE <- gsub("A", "", activedata$UNI_CODE)
# from path date
activedata$LATITUDE <- NA
activedata$LONGITUDE <- NA
for (k in 1:10) {
if (k == 1) {
activedata$LATITUDE[k] <- latLongFile$LATITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
activedata$LONGITUDE[k] <- latLongFile$LONGITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
Arrows(activedata$LONGITUDE[k], activedata$LATITUDE[k] + 0.00015, activedata$LONGITUDE[k], activedata$LATITUDE[k]+ 0.0002, col="green", code = 1,  arr.type="triangle",arr.width = 0.04,arr.length = 0.03, lwd=1.5 )
} else if (k == 10) {
activedata$LATITUDE[k] <- latLongFile$LATITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
activedata$LONGITUDE[k] <- latLongFile$LONGITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
Arrows(activedata$LONGITUDE[k], activedata$LATITUDE[k] + 0.00015, activedata$LONGITUDE[k], activedata$LATITUDE[k]+ 0.0002, col="blue", code = 1,  arr.type="triangle",arr.width = 0.04,arr.length = 0.03, lwd=1.5 )
} else {
activedata$LATITUDE[k] <- latLongFile$LATITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
activedata$LONGITUDE[k] <- latLongFile$LONGITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
Arrows(activedata$LONGITUDE[k], activedata$LATITUDE[k] + 0.00015, activedata$LONGITUDE[k], activedata$LATITUDE[k]+ 0.0002, col="black", code = 1,  arr.type="triangle",arr.width = 0.04,arr.length = 0.03, lwd=1.5 )
}
}
pc = par("usr")
lines(c(-71.49130, -71.49177),
c(-16.42195, -16.42195))
text(x=mean(c(pc[2]-0.0012, pc[2])),
y=pc[3] + 0.06*(pc[4] - pc[3]),
label="50 m", cex=2)
#===================================================================================
#	Fifth day
#===================================================================================
# change all variables for the next day
fromCutOffDate <- rbind(fromCutOffDate, activedata)
activedata <- sactivedata
modelResultName <- "MODEL_RESULTS_13.58_2017-12-19_13_DEC_MODEL_RESULTS_13.59_2017-12-19_14_dec_MODEL_RESULTS_13.60_2017-10-03.combined"
pathDate <- "2017-12-15"
modelResult <- read.csv(file.path("~/PETM-shiny/graph_partition/newModelResults", paste0(modelResultName, ".csv")), sep=" ")
modelResult <- modelResult[which(modelResult$section == as.numeric(sectionN)),]
# subset to only those inspecciones that were done on the pathDate day
activedata <- activedata[which(activedata$FECHA == as.character(as.Date(pathDate, "%Y-%m-%d"))),]
# get only those houses of the username we want
activedata <- activedata[which(activedata$USER_NAME == paste0("r", userActive) | activedata$USER_NAME == paste0("R", userActive)),]
# order everything by FECHA
activedata <- activedata[order(as.POSIXct(activedata$DATETIME, format = "%Y-%m-%d %H:%M:%S")),]
# delete all duplicated rows
activedata <- activedata[!duplicated(activedata$UNI_CODE),]
# make quantiles from the modelOutput probabilities
colPalFuncOutput <- colorRampPalette(
colors = c("#FFFFB2", "#FECC5C", "#FD8D3C", "#F03B20", "#BD0026"),
space = "Lab" # Option used when colors do not represent a quantitative scale
)
# colors used for risk map
outputColors <- colPalFuncOutput(5)
quants <- quantile(modelResult$probability, c(0.20, 0.40, 0.60, 0.80))
modelResult$quant <- with(modelResult, factor(ifelse(probability < quants[1], 0,
ifelse(probability < quants[2], 1,
ifelse(probability < quants[3], 2,
ifelse(probability < quants[4], 3, 4))))))
plot(modelResult[,c('LONGITUDE','LATITUDE')], col=outputColors[modelResult$quant], xaxt='n', yaxt='n', ann=FALSE, pch = 19, cex = 0.8, axes=F)
title(main ="Day 5", line=-17, cex.main=2.5)
fromCutOffDate$UNI_CODE <- gsub("A", "", fromCutOffDate$UNI_CODE)
activedata$UNI_CODE <- gsub("A", "", activedata$UNI_CODE)
# from path date
activedata$LATITUDE <- NA
activedata$LONGITUDE <- NA
for (k in 1:11) {
if (k == 1) {
activedata$LATITUDE[k] <- latLongFile$LATITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
activedata$LONGITUDE[k] <- latLongFile$LONGITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
Arrows(activedata$LONGITUDE[k], activedata$LATITUDE[k] + 0.00015, activedata$LONGITUDE[k], activedata$LATITUDE[k]+ 0.0002, col="green", code = 1,  arr.type="triangle",arr.width = 0.04,arr.length = 0.03, lwd=1.5 )
} else if (k == 11) {
activedata$LATITUDE[k] <- latLongFile$LATITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
activedata$LONGITUDE[k] <- latLongFile$LONGITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
Arrows(activedata$LONGITUDE[k], activedata$LATITUDE[k] + 0.00015, activedata$LONGITUDE[k], activedata$LATITUDE[k]+ 0.0002, col="blue", code = 1,  arr.type="triangle",arr.width = 0.04,arr.length = 0.03, lwd=1.5 )
} else {
activedata$LATITUDE[k] <- latLongFile$LATITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
activedata$LONGITUDE[k] <- latLongFile$LONGITUDE[which(latLongFile$UNICODE == activedata$UNI_CODE[k])]
Arrows(activedata$LONGITUDE[k], activedata$LATITUDE[k] + 0.00015, activedata$LONGITUDE[k], activedata$LATITUDE[k]+ 0.0002, col="black", code = 1,  arr.type="triangle",arr.width = 0.04,arr.length = 0.03, lwd=1.5 )
}
}
pc = par("usr")
lines(c(-71.49130, -71.49177),
c(-16.42195, -16.42195))
text(x=mean(c(pc[2]-0.0012, pc[2])),
y=pc[3] + 0.06*(pc[4] - pc[3]),
label="50 m", cex=2)
# Inspector G app phase
# Inspector E croquis phase
# Inspector E app phase
modelResult <- "MODEL_RESULTS_13.92_2017-09-13.todos"
library(RColorBrewer)
library(leaflet)
library(data.table)
source("~/PETM-shiny/shiny/controller/palettes.R")
lat_long_direc<- file.path(homeDir, "PETM-shiny/unicode_numberMzn/AREQUIPA_GPS_GOOGLE")
latLongFile <- read.csv(file.path(lat_long_direc, "AQP_GPS_GOOGLE_EARTH_PUNTOS_05_jun_2017.csv"))
homeDir <- "~"
lat_long_direc<- file.path(homeDir, "PETM-shiny/unicode_numberMzn/AREQUIPA_GPS_GOOGLE")
latLongFile <- read.csv(file.path(lat_long_direc, "AQP_GPS_GOOGLE_EARTH_PUNTOS_05_jun_2017.csv"))
latLongFile$UNICODE <- as.character(latLongFile$UNICODE)
catchment_area <- read.csv(paste0("~/PETM-shiny/graph_partition/newModelResults/", modelResult, ".csv"), sep = " ")
catchment_area <- catchment_area[which(catchment_area$section == section),]
section <- 0
catchment_area <- read.csv(paste0("~/PETM-shiny/graph_partition/newModelResults/", modelResult, ".csv"), sep = " ")
catchment_area <- catchment_area[which(catchment_area$section == section),]
catchment_area <- as.data.table(catchment_area)
catchment_area$color <- YlOrRd.q(catchment_area[, probability])
modelResult <- "MODEL_RESULTS_13.92_2017-12-04.todos"
catchment_area <- read.csv(paste0("~/PETM-shiny/graph_partition/newModelResults/", modelResult, ".csv"), sep = " ")
catchment_area <- catchment_area[which(catchment_area$section == section),]
catchment_area <- as.data.table(catchment_area)
catchment_area$color <- YlOrRd.q(catchment_area[, probability])
unique(catchment_area$color)
catchment_area2 <- catchment_area
modelResult <- "MODEL_RESULTS_13.92_2017-09-13.todos"
catchment_area <- read.csv(paste0("~/PETM-shiny/graph_partition/newModelResults/", modelResult, ".csv"), sep = " ")
catchment_area <- catchment_area[which(catchment_area$section == section),]
catchment_area <- as.data.table(catchment_area)
catchment_area$color <- YlOrRd.q(catchment_area[, probability])
for (i in 1:nrow(catchment_area)) {
if (catchment_area$UNICODE[i] %in% catchment_area2$UNICODE) {
} else {
print(catchment_area$UNICODE[i])
}
}
plot(catchment_area[,c('LONGITUDE','LATITUDE')], col=catchment_area$color, xaxt='n', yaxt='n', ann=FALSE, pch = 19, cex = 2, axes=F)
plot(catchment_area2[,c('LONGITUDE','LATITUDE')], col=catchment_area2$color, xaxt='n', yaxt='n', ann=FALSE, pch = 19, cex = 2, axes=F)
unique(catchment_area$color)
View(catchment_area2)
View(catchment_area)
for (i in 1:nrow(catchment_area2)) {
if (catchment_area2$UNICODE[i] %in% catchment_area$UNICODE) {
} else {
print(catchment_area$UNICODE2[i])
}
}
for (i in 1:nrow(catchment_area)) {
lat1 <- catchment_area$LATITUDE[i]
lon1 <- catchment_area$LONGITUDE[i]
lat2 <- catchment_area2[which(catchment_area2$LATITUDE == lat1),]
lon2 <- catchment_area2[which(catchment_area2$LONGITUDE == lon1),]
if (lat1 != lat2 | lon1 != lon2) {
print(catchment_area$UNICODE[i])
}
}
i <- 1
lat1 <- catchment_area$LATITUDE[i]
lon1 <- catchment_area$LONGITUDE[i]
lat2 <- catchment_area2[which(catchment_area2$LATITUDE == lat1),]
which(catchment_area2$LATITUDE == lat1)
lat1 <- catchment_area$LATITUDE[i]
lon1 <- catchment_area$LONGITUDE[i]
lat2 <- catchment_area2$LATITUDE[which(catchment_area2$UNICODE == catchment_area$UNICODE[i])]
lon2 <- catchment_area2$LONGITUDE[which(catchment_area2$UNICODE == catchment_area$UNICODE[i])]
for (i in 1:nrow(catchment_area)) {
lat1 <- catchment_area$LATITUDE[i]
lon1 <- catchment_area$LONGITUDE[i]
lat2 <- catchment_area2$LATITUDE[which(catchment_area2$UNICODE == catchment_area$UNICODE[i])]
lon2 <- catchment_area2$LONGITUDE[which(catchment_area2$UNICODE == catchment_area$UNICODE[i])]
if (lat1 != lat2 | lon1 != lon2) {
print(catchment_area$UNICODE[i])
}
}
shiny::runApp('PETM-shiny/shiny')
version
q()
setwd("~/AQP-AI/AI/qValOverTime")
test <- readtext("qValsFriApr1316_03_12PET2018.txt")
install.packages("readtext")
library(readtext)
test <- readtext("qValsFriApr1316_03_12PET2018.txt")
View(test)
View(test)
test
readtext$text
test <- readtable("qValsFriApr1316_03_12PET2018.txt")
test <- read.table("qValsFriApr1316_03_12PET2018.txt")
View(test)
if(!require(data.table)){install.packages("data.table", repos="http://cran.rstudio.com/", dependencies=TRUE)}
library(data.table)
setwd("~/AQP-AI/AI/qValOverTime")
test <- read.table("qValsFriApr1316_03_12PET2018.txt")
View(test)
test[1]
test[[1]]
test$V1
test
plot(1:nrow(toDisplay), toDisplay)
toDisplay <- read.table("qValsFriApr1316_03_12PET2018.txt")
plot(1:nrow(toDisplay), toDisplay)
rm(test)
nrow(toDisplay)
1:nrow(toDisplay)
toDisplay
1:nrow(toDisplay)
plot(1:nrow(toDisplay), toDisplay$V1)
plot(1:nrow(toDisplay), toDisplay$V1, bg="black")
plot(1:nrow(toDisplay), toDisplay$V1, col="black", pch=1)
plot(1:nrow(toDisplay), toDisplay$V1, col="black", pch=2)
plot(1:nrow(toDisplay), toDisplay$V1, col="black", pch=16)
plot(1:nrow(toDisplay), toDisplay$V1, col="black", pch=16, cex=0.8)
plot(1:nrow(toDisplay), toDisplay$V1, col="black", pch=16, cex=0.2)
plot(1:nrow(toDisplay), toDisplay$V1, col="black", pch=16, cex=0.5)
if(!require(data.table)){install.packages("data.table", repos="http://cran.rstudio.com/", dependencies=TRUE)}
library(data.table)
setwd("~/AQP-AI/AI/qValOverTime")
toDisplay <- read.table("qValsFriApr1316_14_46PET2018.txt")
plot(1:nrow(toDisplay), toDisplay$V1, col="black", pch=16, cex=0.5)
plot(1:nrow(toDisplay), toDisplay$V1, col="black", pch=16, cex=0.01)
plot(1:nrow(toDisplay), toDisplay$V1, col="black", pch=16, cex=0.1)
plot(1:nrow(toDisplay), toDisplay$V1, col="black", pch=16, cex=0.5)
# show where the q value curve
# april justin
#===================================================================================
#  Part I: Dependencies, sources, directories
#===================================================================================
if(!require(data.table)){install.packages("data.table", repos="http://cran.rstudio.com/", dependencies=TRUE)}
library(data.table)
#===================================================================================
#  Part II: Read in the file and prepare
#===================================================================================
setwd("~/AQP-AI/AI/qValOverTime")
toDisplay <- read.table("qValsFriApr1316_32_02PET2018.txt")
#===================================================================================
#  Part III: Display curve
#===================================================================================
plot(1:nrow(toDisplay), toDisplay$V1, col="black", pch=16, cex=0.5)
